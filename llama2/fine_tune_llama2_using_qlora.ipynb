{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gupta24789/llms-fine-tuning/blob/main/llama2/fine_tune_llama2_using_qlora.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zQqIy9WuFIFa"
      },
      "source": [
        "## Objective\n",
        "\n",
        "\n",
        "In this notebook, we will fine-tune the **meta-llama/Llama-2-70b-chat-hf** llama2 model\n",
        "\n",
        "\n",
        "Dataset Used : https://www.kaggle.com/datasets/azraimohamad/coursera-course-data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B5XNId_nFIFe"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = \"1\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_oM8LqIWFIFg",
        "outputId": "c38776f8-41ac-49b7-b625-1c56788d9753"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "from datasets import load_dataset\n",
        "from dotenv import load_dotenv\n",
        "from pprint import pprint\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig,TrainingArguments,pipeline,logging\n",
        "from peft import LoraConfig, prepare_model_for_kbit_training, get_peft_model, AutoPeftModelForCausalLM, PeftModel\n",
        "from trl import SFTTrainer\n",
        "load_dotenv()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YsxrLynIFIFi"
      },
      "source": [
        "## Transform Data\n",
        "\n",
        "Data Format:\n",
        "\n",
        "        <s> [INST] prompt [/INST] response </s>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HjOFc46sFIFj",
        "outputId": "c3dfe640-b96b-4401-ae23-201ba6437c08"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Skills': ' Network Security, Python Programming, Linux, Cloud Computing, '\n",
            "           'Algorithms, Audit, Computer Programming, Computer Security '\n",
            "           'Incident Management, Cryptography, Databases, Leadership and '\n",
            "           'Management, Network Architecture, Risk Management, SQL',\n",
            " 'Title': 'Google Cybersecurity'}\n"
          ]
        }
      ],
      "source": [
        "dataset = load_dataset(\"csv\", data_dir=\"data\",data_files= \"coursera_course_dataset_v3.csv\")\n",
        "dataset = dataset.select_columns(['Title','Skills'])\n",
        "pprint(dataset['train'][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n34ePaprFIFk"
      },
      "outputs": [],
      "source": [
        "def transform_data(row):\n",
        "    title = row['Title'].strip()\n",
        "    skills = row['Skills'].strip()\n",
        "    text = f\"<s> [INST] Skills related with : {title} [/INST] {skills}</s>\"\n",
        "    return {\"text\": text}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-PsZn7VNFIFk",
        "outputId": "2921ca14-1a9e-472d-c056-bd49a63435a5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['Title', 'Skills', 'text'],\n",
              "        num_rows: 623\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset = dataset.map(transform_data)\n",
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "guwKcvaVFIFl",
        "outputId": "9fc33710-7f10-4dbc-c56a-eb3eec7d4330"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Skills': ' Network Security, Python Programming, Linux, Cloud Computing, '\n",
            "           'Algorithms, Audit, Computer Programming, Computer Security '\n",
            "           'Incident Management, Cryptography, Databases, Leadership and '\n",
            "           'Management, Network Architecture, Risk Management, SQL',\n",
            " 'Title': 'Google Cybersecurity',\n",
            " 'text': '<s> [INST] Skills related with : Google Cybersecurity [/INST] '\n",
            "         'Network Security, Python Programming, Linux, Cloud Computing, '\n",
            "         'Algorithms, Audit, Computer Programming, Computer Security Incident '\n",
            "         'Management, Cryptography, Databases, Leadership and Management, '\n",
            "         'Network Architecture, Risk Management, SQL</s>'}\n"
          ]
        }
      ],
      "source": [
        "pprint(dataset['train'][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VSQ6A_MDFIFm"
      },
      "outputs": [],
      "source": [
        "## Push to hub\n",
        "# dataset.push_to_hub(\"sg247/coursera-course-data\", token = os.environ['HF_WRITE_TOKEN'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yiz-YQLDFIFm"
      },
      "source": [
        "## Fine Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WpifF_wSFIFn",
        "outputId": "3dc822c3-4fd4-47c9-9752-1204f92fd599"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['Title', 'Skills', 'text'],\n",
              "    num_rows: 623\n",
              "})"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset = load_dataset(\"sg247/coursera-course-data\", split = 'train')\n",
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rFCr0_5NFIFn",
        "outputId": "a90499e0-b9c5-4eab-b2ee-a0dd7a392bc9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Skills': ' Machine Learning, Deep Learning, Artificial Neural Networks, '\n",
            "           'Machine Learning Algorithms, Applied Machine Learning, Python '\n",
            "           'Programming, Machine Learning Software, Network Model, Algorithms, '\n",
            "           'Computer Programming, Computer Vision, Network Architecture, '\n",
            "           'Natural Language Processing, Tensorflow, Human Learning, Data '\n",
            "           'Analysis, Data Model, Exploratory Data Analysis, Organizational '\n",
            "           'Development, Process Analysis, Strategy, Computational Logic, '\n",
            "           'Mathematics, Mathematical Theory & Analysis, Linear Algebra, '\n",
            "           'Regression, Calculus',\n",
            " 'Title': 'Deep Learning',\n",
            " 'text': '<s> [INST] Skills related with : Deep Learning [/INST] Machine '\n",
            "         'Learning, Deep Learning, Artificial Neural Networks, Machine '\n",
            "         'Learning Algorithms, Applied Machine Learning, Python Programming, '\n",
            "         'Machine Learning Software, Network Model, Algorithms, Computer '\n",
            "         'Programming, Computer Vision, Network Architecture, Natural Language '\n",
            "         'Processing, Tensorflow, Human Learning, Data Analysis, Data Model, '\n",
            "         'Exploratory Data Analysis, Organizational Development, Process '\n",
            "         'Analysis, Strategy, Computational Logic, Mathematics, Mathematical '\n",
            "         'Theory & Analysis, Linear Algebra, Regression, Calculus</s>'}\n"
          ]
        }
      ],
      "source": [
        "pprint(dataset[17])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SeKIQhsfFIFo"
      },
      "source": [
        "## bitsandbytes parameters\n",
        "\n",
        "- **bnb_4bit_compute_dtype** (torch.dtype or str, optional, defaults to torch.float32) — This sets the computational type which might be different than the input time. For example, inputs might be fp32, but computation can be set to bf16 for speedups.\n",
        "\n",
        "- **load_in_4bit** (bool, optional, defaults to False) — This flag is used to enable 4-bit quantization by replacing the Linear layers with FP4/NF4 layers from bitsandbytes.\n",
        "\n",
        "- **bnb_4bit_quant_type** (str, optional, defaults to \"fp4\") — This sets the quantization data type in the bnb.nn.Linear4Bit layers. Options are FP4 and NF4 data types which are specified by fp4 or nf4.\n",
        "\n",
        "- **bnb_4bit_use_double_quant** (bool, optional, defaults to False) — This flag is used for nested quantization where the quantization constants from the first quantization are quantized again."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XR6DW8n4FIFp"
      },
      "outputs": [],
      "source": [
        "## Quantization\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit= True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype= torch.float16,\n",
        "    bnb_4bit_use_double_quant= True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lIK_BKG7FIFq"
      },
      "source": [
        "## Load Model & Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zIngGpIyFIFq",
        "outputId": "1ca4021e-00f0-4656-c970-6871c31df4a4",
        "colab": {
          "referenced_widgets": [
            "a3b8070a986b42b09eca5f236227a6e9"
          ]
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a3b8070a986b42b09eca5f236227a6e9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "## Model-Name\n",
        "model_name = \"meta-llama/Llama-2-7b-chat-hf\"\n",
        "\n",
        "# Load base model\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    quantization_config=bnb_config,\n",
        "    device_map= {\"\":0},\n",
        "    token = os.environ['HF_READ_TOKEN']\n",
        ")\n",
        "model.config.use_cache = False\n",
        "model.config.pretraining_tp = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jmx0fodoFIFr"
      },
      "outputs": [],
      "source": [
        "# Load LLaMA tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, token=os.environ['HF_READ_TOKEN'], trust_remote_code=True)\n",
        "# tokenizer.pad_token = '[PAD]'\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "tokenizer.padding_side = \"right\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EGyQu50RFIFr"
      },
      "source": [
        "## Inference Before Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "twN4Ux0xFIFs"
      },
      "outputs": [],
      "source": [
        "df = dataset.to_pandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PalzUZPQFIFs",
        "outputId": "36ad8fb8-ee5d-4d12-ccd7-3597ac5cc93f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input Prompt : <s>[INST] Skills related with : Deep Learning [/INST]\n",
            "---------------------------------------------------------------------------------------------------\n",
            "Skills :  Machine Learning, Deep Learning, Artificial Neural Networks, Machine Learning Algorithms, Applied Machine Learning, Python Programming, Machine Learning Software, Network Model, Algorithms, Computer Programming, Computer Vision, Network Architecture, Natural Language Processing, Tensorflow, Human Learning, Data Analysis, Data Model, Exploratory Data Analysis, Organizational Development, Process Analysis, Strategy, Computational Logic, Mathematics, Mathematical Theory & Analysis, Linear Algebra, Regression, Calculus\n",
            "---------------------------------------------------------------------------------------------------\n",
            "  Deep learning is a subset of machine learning that involves the use of artificial neural networks to analyze and interpret complex data. Unterscheidung between deep learning and other machine-learning techniques is largely based on the size and complexity of the data sets that can be handled. Here are some key skills related to deep- learning:\n",
            "\n",
            "1. Programming skills: Deep-learnin g requires proficiency in programming languages such as Python, Java, C++, and R. Knowledge of popular deep -learning frameworks such a s TensorFlow, PyTorch, and\n"
          ]
        }
      ],
      "source": [
        "title = \"Deep Learning\"\n",
        "prompt = f\"<s>[INST] Skills related with : {title} [/INST]\"\n",
        "related_skills = df[df.Title==title]['Skills'].values[0]\n",
        "pipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer,\n",
        "                max_length=128, do_sample = True, top_k = 10, no_repeat_ngram_size = 2)\n",
        "result = pipe(prompt)\n",
        "dash_line = '-'.join('' for x in range(100))\n",
        "\n",
        "print(f\"Input Prompt : {prompt}\")\n",
        "print(dash_line)\n",
        "print(f\"Skills : {related_skills}\")\n",
        "print(dash_line)\n",
        "print(result[0]['generated_text'][len(prompt):])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CrLO_EyEFIFs"
      },
      "source": [
        "## Training Setup\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQ-h7qwrFIFt"
      },
      "source": [
        "# QLoRA parameters\n",
        "\n",
        "- task_type: the task to train for (sequence-to-sequence language modeling in this case)\n",
        "- inference_mode: whether you’re using the model for inference or not\n",
        "- r: the dimension of the low-rank matrices\n",
        "- lora_alpha: the scaling factor for the low-rank matrices\n",
        "- lora_dropout: the dropout probability of the LoRA layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XHpGapFLFIFt"
      },
      "outputs": [],
      "source": [
        "def print_trainable_parameters(model):\n",
        "    \"\"\"\n",
        "    Prints the number of trainable parameters in the model.\n",
        "    \"\"\"\n",
        "    trainable_params = 0\n",
        "    all_param = 0\n",
        "    for _, param in model.named_parameters():\n",
        "\n",
        "        all_param += param.numel()\n",
        "        if param.requires_grad:\n",
        "            trainable_params += param.numel()\n",
        "    print(\n",
        "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JIB-5HacFIFt",
        "outputId": "27636f2b-68c2-4cc8-b8aa-f4cfc0b12c71"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LlamaForCausalLM(\n",
            "  (model): LlamaModel(\n",
            "    (embed_tokens): Embedding(32000, 4096)\n",
            "    (layers): ModuleList(\n",
            "      (0-31): 32 x LlamaDecoderLayer(\n",
            "        (self_attn): LlamaAttention(\n",
            "          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
            "          (k_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
            "          (v_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
            "          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
            "          (rotary_emb): LlamaRotaryEmbedding()\n",
            "        )\n",
            "        (mlp): LlamaMLP(\n",
            "          (gate_proj): Linear4bit(in_features=4096, out_features=11008, bias=False)\n",
            "          (up_proj): Linear4bit(in_features=4096, out_features=11008, bias=False)\n",
            "          (down_proj): Linear4bit(in_features=11008, out_features=4096, bias=False)\n",
            "          (act_fn): SiLU()\n",
            "        )\n",
            "        (input_layernorm): LlamaRMSNorm()\n",
            "        (post_attention_layernorm): LlamaRMSNorm()\n",
            "      )\n",
            "    )\n",
            "    (norm): LlamaRMSNorm()\n",
            "  )\n",
            "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "model.gradient_checkpointing_enable()\n",
        "model = prepare_model_for_kbit_training(model)\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hDot88uHFIFu",
        "outputId": "19abb68b-f87f-47e0-ad1a-e1a43fb658d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trainable params: 33554432 || all params: 3533967360 || trainable%: 0.9494833591219133\n"
          ]
        }
      ],
      "source": [
        "## Lora config\n",
        "lora_config = LoraConfig(\n",
        "    r= 32,\n",
        "    lora_alpha=64,\n",
        "    lora_dropout=0.1,\n",
        "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"], #specific to Llama models.\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\",\n",
        ")\n",
        "\n",
        "model = get_peft_model(model, lora_config)\n",
        "print_trainable_parameters(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6GzhYv06FIFu"
      },
      "source": [
        "## Training Argument"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qkFBXkwPFIFu",
        "outputId": "46144881-feb2-4bb5-9d4d-912ec26d168d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
          ]
        }
      ],
      "source": [
        "CHECKPOINTS_DIR = \"results\"\n",
        "\n",
        "training_arguments = TrainingArguments(\n",
        "    per_device_train_batch_size=4,\n",
        "    gradient_accumulation_steps=4,\n",
        "    optim=\"paged_adamw_32bit\",\n",
        "    logging_steps=5,\n",
        "    learning_rate=1e-4,\n",
        "    fp16=True,\n",
        "    max_grad_norm=0.3,\n",
        "    num_train_epochs=1,\n",
        "    warmup_ratio=0.05,\n",
        "    save_strategy=\"steps\",\n",
        "    group_by_length=True,\n",
        "    output_dir=CHECKPOINTS_DIR,\n",
        "    report_to=\"tensorboard\",\n",
        "    save_safetensors=True,\n",
        "    lr_scheduler_type=\"cosine\",\n",
        "    seed=42,\n",
        ")\n",
        "model.config.use_cache = False  # silence the warnings. re-enable for inference!\n",
        "\n",
        "## SFT Trainer\n",
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    train_dataset=dataset,\n",
        "    eval_dataset= None,\n",
        "    peft_config=lora_config,\n",
        "    dataset_text_field=\"text\",\n",
        "    max_seq_length=512,\n",
        "    tokenizer=tokenizer,\n",
        "    args=training_arguments\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9XSYGgiFIFv"
      },
      "source": [
        "# Train model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q6tzuLwCFIFv",
        "outputId": "be0efea8-f98f-4b71-edb7-ee5f15cb3f52"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='39' max='39' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [39/39 02:12, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>3.319300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>3.400000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>1.914700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1.663100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>1.278100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>1.223400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>1.156600</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=39, training_loss=1.9057974081773024, metrics={'train_runtime': 135.8295, 'train_samples_per_second': 4.587, 'train_steps_per_second': 0.287, 'total_flos': 1810096299147264.0, 'train_loss': 1.9057974081773024, 'epoch': 1.0})"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dYbC4i4dFIFv"
      },
      "source": [
        "# Save trained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wKI1_-jUFIFw"
      },
      "outputs": [],
      "source": [
        "# from huggingface_hub import notebook_login\n",
        "# notebook_login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tBg4_qfZFIFw"
      },
      "outputs": [],
      "source": [
        "## If you will get the access error then uncomment and run above cell\n",
        "peft_model_path = \"./finetuned-chat-llama2\"\n",
        "tokenizer.save_pretrained(peft_model_path)\n",
        "trainer.model.save_pretrained(peft_model_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGlnnmdbFIFw"
      },
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YPI9R45NFIFw"
      },
      "outputs": [],
      "source": [
        "# Ignore warnings\n",
        "logging.set_verbosity(logging.CRITICAL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y5hN9nKXFIFx",
        "outputId": "8047875b-730e-425c-afa4-c769a0e173ab"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "PeftModelForCausalLM(\n",
              "  (base_model): LoraModel(\n",
              "    (model): LlamaForCausalLM(\n",
              "      (model): LlamaModel(\n",
              "        (embed_tokens): Embedding(32000, 4096)\n",
              "        (layers): ModuleList(\n",
              "          (0-31): 32 x LlamaDecoderLayer(\n",
              "            (self_attn): LlamaAttention(\n",
              "              (q_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=4096, out_features=32, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=32, out_features=4096, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "              )\n",
              "              (k_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=4096, out_features=32, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=32, out_features=4096, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "              )\n",
              "              (v_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=4096, out_features=32, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=32, out_features=4096, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "              )\n",
              "              (o_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=4096, out_features=32, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=32, out_features=4096, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "              )\n",
              "              (rotary_emb): LlamaRotaryEmbedding()\n",
              "            )\n",
              "            (mlp): LlamaMLP(\n",
              "              (gate_proj): Linear4bit(in_features=4096, out_features=11008, bias=False)\n",
              "              (up_proj): Linear4bit(in_features=4096, out_features=11008, bias=False)\n",
              "              (down_proj): Linear4bit(in_features=11008, out_features=4096, bias=False)\n",
              "              (act_fn): SiLU()\n",
              "            )\n",
              "            (input_layernorm): LlamaRMSNorm()\n",
              "            (post_attention_layernorm): LlamaRMSNorm()\n",
              "          )\n",
              "        )\n",
              "        (norm): LlamaRMSNorm()\n",
              "      )\n",
              "      (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.config.use_cache = True\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j5J3h_EMFIFx",
        "outputId": "123c28b7-e64f-420b-fc6d-64c00bb83c55"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input Prompt : <s>[INST] Skills related with : Deep Learning [/INST]\n",
            "---------------------------------------------------------------------------------------------------\n",
            "Skills :  Machine Learning, Deep Learning, Artificial Neural Networks, Machine Learning Algorithms, Applied Machine Learning, Python Programming, Machine Learning Software, Network Model, Algorithms, Computer Programming, Computer Vision, Network Architecture, Natural Language Processing, Tensorflow, Human Learning, Data Analysis, Data Model, Exploratory Data Analysis, Organizational Development, Process Analysis, Strategy, Computational Logic, Mathematics, Mathematical Theory & Analysis, Linear Algebra, Regression, Calculus\n",
            "---------------------------------------------------------------------------------------------------\n",
            " Deep learning, Machine Learning, Neural Networks, Artificial Neuration, Computer Networking, Data Management, Network Architecture, Statistical Learning\n",
            " nobody, probability, statistics, data analysis, machine learning software, statistical inference, neural network, deep learning platform, computer vision, convolutional neural networks, natural language processing, generative adversarial networks\n",
            "), Deep Network Learning (Deep Learning), Machine Programming, Programmatic Development, Python Programmer, Software Engineering, TensorFlow, Algorithms, Applied Mathematics, Cloud Applications,\n"
          ]
        }
      ],
      "source": [
        "title = \"Deep Learning\"\n",
        "prompt = f\"<s>[INST] Skills related with : {title} [/INST]\"\n",
        "related_skills = df[df.Title==title]['Skills'].values[0]\n",
        "pipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer,\n",
        "                max_length=128, do_sample = True, top_k = 10, no_repeat_ngram_size = 2)\n",
        "result = pipe(prompt)\n",
        "dash_line = '-'.join('' for x in range(100))\n",
        "\n",
        "print(f\"Input Prompt : {prompt}\")\n",
        "print(dash_line)\n",
        "print(f\"Skills : {related_skills}\")\n",
        "print(dash_line)\n",
        "print(result[0]['generated_text'][len(prompt):])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GUT8pv-DFIFx",
        "outputId": "ec3a05db-8723-4aea-cf88-48ddfdaa02c8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "del model\n",
        "del tokenizer\n",
        "import gc\n",
        "gc.collect()\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M88r8WuMFIFy"
      },
      "source": [
        "## Save full model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o3OoVK8nFIFy",
        "outputId": "ced9a5ed-17b7-485a-9948-cbb9b2bfba4b",
        "colab": {
          "referenced_widgets": [
            "2b50264b30ed442aba9b7647ba7704d1"
          ]
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2b50264b30ed442aba9b7647ba7704d1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input Prompt : <s>[INST] Skills related with : Deep Learning [/INST]\n",
            "---------------------------------------------------------------------------------------------------\n",
            "Skills :  Machine Learning, Deep Learning, Artificial Neural Networks, Machine Learning Algorithms, Applied Machine Learning, Python Programming, Machine Learning Software, Network Model, Algorithms, Computer Programming, Computer Vision, Network Architecture, Natural Language Processing, Tensorflow, Human Learning, Data Analysis, Data Model, Exploratory Data Analysis, Organizational Development, Process Analysis, Strategy, Computational Logic, Mathematics, Mathematical Theory & Analysis, Linear Algebra, Regression, Calculus\n",
            "---------------------------------------------------------------------------------------------------\n",
            " Artificial Neural Networks, Deep Neuro Learning, Neuron, Machine Learning Algorithms, Natural Language Processing, Regression, Computer Networking\n",
            ", Computational Neuroscience, Data Analysis, General Statistics, Information Theory, Linear Algebra, Probability & Statistics\n",
            "... [more]\n",
            "Computational Ne Neurol, Artif Intelligence, Business Intelli, Cryptography, Human Learning\n",
            "Data Analysis Software, Python Programming, Spatial Analysis\n",
            "Artific, Statistics Comput, Statistical Machine Learn, Time Series\n"
          ]
        }
      ],
      "source": [
        "# Reload model in FP16 and merge it with LoRA weights\n",
        "base_model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    low_cpu_mem_usage=True,\n",
        "    return_dict=True,\n",
        "    torch_dtype=torch.float16,\n",
        "    device_map={\"\":0},\n",
        ")\n",
        "model = PeftModel.from_pretrained(base_model, peft_model_path)\n",
        "model = model.merge_and_unload()\n",
        "\n",
        "# Reload tokenizer to save it\n",
        "tokenizer = AutoTokenizer.from_pretrained(peft_model_path)\n",
        "\n",
        "\n",
        "## Inference\n",
        "title = \"Deep Learning\"\n",
        "prompt = f\"<s>[INST] Skills related with : {title} [/INST]\"\n",
        "related_skills = df[df.Title==title]['Skills'].values[0]\n",
        "pipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer,\n",
        "                max_length=128, do_sample = True, top_k = 10, no_repeat_ngram_size = 2)\n",
        "result = pipe(prompt)\n",
        "dash_line = '-'.join('' for x in range(100))\n",
        "\n",
        "print(f\"Input Prompt : {prompt}\")\n",
        "print(dash_line)\n",
        "print(f\"Skills : {related_skills}\")\n",
        "print(dash_line)\n",
        "print(result[0]['generated_text'][len(prompt):])"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "lighting",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}